{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from fastai.text.all import *\n",
    "import torch\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример работы токенайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4441, 2433, 13124]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode('Это пример текста')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это пример текста'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.LongTensor(ids)[None]\n",
    "preds = model.generate(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 20]),\n",
       " tensor([ 4441,  2433, 13124,    16,  1029,   417,   322,  2447,  7869,    16,\n",
       "           515,  1029,   417,  2447,  7869,    16,   753,   387, 10668,    16]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape,preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это пример текста, который я не могу привести, но который я могу привести, чтобы вы поняли,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываем датасет с анекдотами на русском языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"extract_dialogues_from_anekdots.txt\", 'r',encoding='utf-8') as file:\n",
    "    file_content = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем текст на отдельные диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file_content.split(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [range_of(data), list(range(len(data), len(all_texts)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем батч сайз равным 4, а максимальное число токенов равным 256 (в гпт2 использовалось 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 4,256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='87721' class='' max='87721' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [87721/87721 00:13&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В методе encodes мы учитываем случай, когда мы получаем что-то, что еще не было токенизировано, на случай, если мы будем создавать набор данных с новыми текстами, используя это преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем с помощью встроеной функции TfmdLists методы из TransformersTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n- Скажи, дорогой, как это ты, такой умный и красивый, женился именно на мне?\\n- А, тебя это тоже удивляет...\\n- Мойше, ты слышал, что внук Иоськи спит с мальчиками???\\n- Что ты говоришь, но хотя бы с еврейскими??\\n- Фамилия?\\n- Чья?\\n- Имя?\\n- Чье?\\n- Чья Чье? Мексиканец, что ли?\\n- Скажите, вы выпиваете?\\n- Да, но это потом, сначала о деле.\\n- Я здесь вчера ужинал?\\n- Тут.\\n- А 10 тысяч долларов я у вас пропил7 - У нас.\\n- Ф-фу... Слава Богу, а я думал, что потерял!\\n- Доктор, мой муж импотент на все 200 процентов!\\n- Как так?! Ну на сто процентов я понимаю...\\n- Так оно и было, но вчера он запнулся и прикусил язык.\\n- Я выпил бы что-нибудь безалкогольное.\\n- Лимонад, сок, минеральная вода?\\n- Мне все равно, я в этой области дилетант...\\n- Скажите, кто это? В.И. -...\\n- Мы вам подска</td>\n",
       "      <td>- Скажи, дорогой, как это ты, такой умный и красивый, женился именно на мне?\\n- А, тебя это тоже удивляет...\\n- Мойше, ты слышал, что внук Иоськи спит с мальчиками???\\n- Что ты говоришь, но хотя бы с еврейскими??\\n- Фамилия?\\n- Чья?\\n- Имя?\\n- Чье?\\n- Чья Чье? Мексиканец, что ли?\\n- Скажите, вы выпиваете?\\n- Да, но это потом, сначала о деле.\\n- Я здесь вчера ужинал?\\n- Тут.\\n- А 10 тысяч долларов я у вас пропил7 - У нас.\\n- Ф-фу... Слава Богу, а я думал, что потерял!\\n- Доктор, мой муж импотент на все 200 процентов!\\n- Как так?! Ну на сто процентов я понимаю...\\n- Так оно и было, но вчера он запнулся и прикусил язык.\\n- Я выпил бы что-нибудь безалкогольное.\\n- Лимонад, сок, минеральная вода?\\n- Мне все равно, я в этой области дилетант...\\n- Скажите, кто это? В.И. -...\\n- Мы вам подскажем</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>обвиняли в ограблении магазина.\\n- Да? Как интересно! И какой срок ты ему дал, любимый?\\n- Пришлось освободить. У него оказалось железное алиби: в это время он грабил ба\\n- Василий Иваныч, что такое \"сексуальная прелюдия\"?\\n- Да это, Петька, то, что у нас с Анкой только на людях.\\n- Доктор, а ходить я буду?\\n- Конечно будете,...под себя.\\n- Ну, как там наша Мэри поживает?\\n- Она умерла.\\n- Умерла?!!\\n- Да, умерла от гонореи.\\n- Да ну, люди не умирают от гонореи!\\n- Умирают, если ты заразила ею БОЛЬШОГО ДЖО....\\n- Вахтанг, что такоэ Тыбет?\\n- Э, Гоги, Тыбет это то же что и минэт, толко нэ минэ а тыбе.\\n- Что было между тобой и соседом?\\n- Ничего, даже пижамы.\\n- Папа, что такое \"критика сверху\" и \"критика снизу\"?\\n- Сейчас обьясню... Папа берет табуретку, становится на нее, и - ТЬФУ!</td>\n",
       "      <td>яли в ограблении магазина.\\n- Да? Как интересно! И какой срок ты ему дал, любимый?\\n- Пришлось освободить. У него оказалось железное алиби: в это время он грабил ба\\n- Василий Иваныч, что такое \"сексуальная прелюдия\"?\\n- Да это, Петька, то, что у нас с Анкой только на людях.\\n- Доктор, а ходить я буду?\\n- Конечно будете,...под себя.\\n- Ну, как там наша Мэри поживает?\\n- Она умерла.\\n- Умерла?!!\\n- Да, умерла от гонореи.\\n- Да ну, люди не умирают от гонореи!\\n- Умирают, если ты заразила ею БОЛЬШОГО ДЖО....\\n- Вахтанг, что такоэ Тыбет?\\n- Э, Гоги, Тыбет это то же что и минэт, толко нэ минэ а тыбе.\\n- Что было между тобой и соседом?\\n- Ничего, даже пижамы.\\n- Папа, что такое \"критика сверху\" и \"критика снизу\"?\\n- Сейчас обьясню... Папа берет табуретку, становится на нее, и - ТЬФУ!\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение на новых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь нам нужно написать событие after_pred и заменить self.learn.pred (содержащий предсказания, которые будут переданы функции потерь) только его первым элементом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем результат validation loss = 3.2, perplexity = 25.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.151185</td>\n",
       "      <td>3.160435</td>\n",
       "      <td>23.580856</td>\n",
       "      <td>53:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Чтобы сдать экзамен по искуственному интеллекту нужно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.model.generate(inp, max_length=20, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Чтобы сдать экзамен по искуственному интеллекту нужно, чтобы его не было?\\n- Да, конечно,'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
